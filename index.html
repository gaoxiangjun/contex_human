<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>ConTex-Human: Free-View Rendering of Human from a Single Image with Texture-Consistent Synthesis</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="ConTex-Human: Free-View Rendering of Human from a Single Image with Texture-Consistent Synthesis" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>

    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">ConTex-Human: Free-View Rendering of Human from a Single Image with Texture-Consistent Synthesis</h1>
            <div class="nerf_subheader_v2">Arxiv 2023</div>
            <div class="nerf_subheader_v2">
                <div>
                    <a  target="_blank" class="nerf_authors_v2">Xiangjun Gao<span
                            class="text-span_nerf"></span></a><sup> 1</sup>,&nbsp;&nbsp;
                    <a href="https://xiaoyu258.github.io/" target="_blank" class="nerf_authors_v2">Xiaoyu Li<span
                            class="text-span_nerf"></span></a><sup> 2</sup>,&nbsp;&nbsp;
                    <a  target="_blank" class="nerf_authors_v2">Chaopeng Zhang<span
                            class="text-span_nerf"></span></a><sup> 2</sup>,&nbsp;&nbsp;
                    <a href="https://qzhang-cv.github.io/" target="_blank" class="nerf_authors_v2">Qi Zhang<span
                            class="text-span_nerf"></span></a><sup> 2</sup>,&nbsp;&nbsp;                   
                    <a href="https://yanpei.me/" target="_blank" class="nerf_authors_v2">Yanpei Cao<span
                            class="text-span_nerf"></span></a><sup> 2</sup>,&nbsp;&nbsp;
                    <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank" class="nerf_authors_v2">Ying Shan<span
                            class="text-span_nerf"></span></a><sup> 2</sup>,&nbsp;&nbsp;
                    <a href="https://scholar.google.com/citations?hl=en&user=ZMLhZJ8AAAAJ&view_op=list_works" target="_blank" class="nerf_authors_v2">Long Quan<span
                            class="text-span_nerf"></span></a><sup> 1</sup>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>HKUST</h1>,
                    <h1 class="nerf_affiliation_v2"><sup>2 </sup>Tencent AI Lab</h1>
                </div>

                <div class="external-link">
                    <a class="btn" href="https://arxiv.org/abs/2311.17123" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn" href="paper/ConTex_Human.pdf" role="button" target="_blank">
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="https://github.com/gaoxiangjun/ConTex-Human" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <!-- <a class="btn btn-large btn-light" href="https://youtu.be" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a> -->
                </div>

            </div>
        </div>

    </div>

    

    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <p class="paragraph-3 nerf_text nerf_results_text">
                <b><i>TL;DR: &nbsp; &nbsp;</i> </b> 
                ConTex-Human is a single image to 3D Human model that enables texture-consistent and high-fidelity free view human rendering.
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <div class="grid-container-1">
            <img src="assets/teaser.png">
        </div>
    </div>

    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                In this work, we propose a method to address the challenge of rendering a 3D human from a single image in a free-view manner. 
                Some existing approaches could achieve this by using generalizable pixel-aligned implicit fields to reconstruct a textured mesh of a human 
                or by employing a 2D diffusion model as guidance with the Score Distillation Sampling (SDS) method, to lift the 2D image into 3D space. 
                However, a generalizable implicit field often results in an over-smooth texture field, while the SDS method tends to lead to a texture-inconsistent novel view with the input image. 
                In this paper, we introduce a texture-consistent back view synthesis module that could transfer the reference image content to the back view through depth and text-guided attention injection. 
                Moreover, to alleviate the color distortion that occurs in the side region, we propose a visibility-aware patch consistency regularization 
                for texture mapping and refinement combined with the synthesized back view texture. With the above techniques, we could achieve high-fidelity and texture-consistent human rendering from a single image. 
                Experiments conducted on both real and synthetic data demonstrate the effectiveness of our method and show that our approach outperforms previous baseline methods. 
                <br>
            </p>
        </div>
    </div>

    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Method Overview</h2>
        <div class="grid-container-1">
            <img src="assets/overview_pipeline.png">
            <p style="font-size: 15px;font-family: Ubuntu; text-align: justify;">Our framework is composed of three main stages. 
                (1)Coarse Stage. Given a human image as reference, we leverage view-aware 2D diffusion model Zero123 to conduct (SDS) to optimize a NeRF. 
                (2)Back view Synthesis Stage. Coarse image and depth map are utilized to generate texture-consistent and high-fidelity back view. 
                (3)Fine Stage. We convert NeRF to DMTet Mesh and optimize mesh with front/back normal map. Texture field is optimized with front/back image, 
                Zero123 / Stable-Diffusion SDS, and visibility-aware patch consistency regularization.
            </p>
        </div>
    </div>


    <!-- <div class="white_section_nerf  w-container">
        <div class="grid-container-1">
            <div>
                <video class="video" id="1" loop playsinline autoPlay muted
                src="assets/gallery.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
        </div>
    </div> -->

    
    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Comparison with TeCH</h2>
        <div class="grid-container-1">
            <div>
                <!-- <p class="myprompt nerf_text">A boy in mohawk hairstyle, head only, 4K, HD, raw</p> -->
                <video class="video" id="10" loop playsinline autoPlay muted controls
                src="assets/comp_tech.mp4" onplay="resizeAndPlay(this)"></video>
                <!-- <canvas class="videoMerge" id="10_merge"></canvas> -->
            </div>
            <!-- <div>
                <p class="myprompt nerf_text">Fire-breathing Phoenix, mythical bird, engulfed in flames, <br>rebirth and renewal, 3D render, 8K, HD</p>
                <video class="video" id="11" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/Phoenix7_appearance3.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="11_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A bulldog wearing a black pirate hat, highly detailed</p>
                <video class="video" id="12" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/dog_appearance8.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="12_merge"></canvas>
            </div>
            <div>
                <p class="myprompt nerf_text">A 3D model of mini China town, highly detailed, 8K, HD, blender 3d</p>
                <video class="video" id="13" loop playsinline autoPlay muted
                src="assets/videos/dmtet-based/2023_10_05/ChinaTown0_appearance.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas class="videoMerge" id="13_merge"></canvas>
            </div> -->
        </div>

        <!-- <div class="grid-container-1">
            <a class="mybtn" href="dmtet-based-gallery_0.html" role="button">
            More Results </a>
        </div> -->
    </div>



    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Results on SSHQ</h2>
        <div class="grid-container-1">
            <div>
                <!-- <p class="myprompt nerf_text">A dragon-cat hybrid <br>&nbsp</p> -->
                <video class="video" id="1" loop playsinline autoPlay muted controls
                src="assets/comp_sshq_1.mp4" onplay="resizeAndPlay(this)"></video>
                <!-- <canvas class="videoMerge" id="1_merge"></canvas> -->
            </div>
        </div>
        <div class="grid-container-1">
            <div>
                <!-- <p class="myprompt nerf_text">A dragon-cat hybrid <br>&nbsp</p> -->
                <video class="video" id="1" loop playsinline autoPlay muted controls
                src="assets/comp_sshq_2.mp4" onplay="resizeAndPlay(this)"></video>
                <!-- <canvas class="videoMerge" id="1_merge"></canvas> -->
            </div>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Results on THuman2.0</h2>
        <div class="grid-container-1">
            <div>
                <video class="video" id="1" loop playsinline autoPlay muted controls
                src="assets/comp_thuman_1.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
        </div>
        <div class="grid-container-1">
            <div>
                <video class="video" id="1" loop playsinline autoPlay muted controls
                src="assets/comp_thuman_2.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
        </div>

    </div>
    
    

    
<div class="white_section_nerf grey_container w-container">
<h2 class="grey-heading_nerf">BibTeX</h2>
<div class="bibtex">
    <pre><code>
	    @misc{gao2023contexhuman,
      title={ConTex-Human: Free-View Rendering of Human from a Single Image with Texture-Consistent Synthesis}, 
      author={Xiangjun Gao and Xiaoyu Li and Chaopeng Zhang and Qi Zhang and Yanpei Cao and Ying Shan and Long Quan},
      year={2023},
      eprint={2311.17123},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
    </code></pre>
</div>
</div>

</body>
<footer>
    This project page template is inspired by <a href="https://sweetdreamer3d.github.io/">SweetDreamer.</a>
</footer>

</html>
